{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "955608bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as pt\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from pyconll import iter_from_file\n",
    "\n",
    "from tokenizer import train_mopiece, MOPiece\n",
    "\n",
    "import regex as re\n",
    "\n",
    "from word_autoencoder import WordEncoder, WordDecoder\n",
    "from dependency_parser import DependencyParser\n",
    "from moplm import Transformer, MOPLM\n",
    "\n",
    "from tqdm.notebook import trange, tqdm\n",
    "\n",
    "device = ('cuda' if pt.cuda.is_available() else 'mps' if pt.backends.mps.is_available() else 'cpu')\n",
    "\n",
    "with open(r'data\\morphynet\\prefixes.csv') as file:\n",
    "    prefixes = [s[:-1] for s in file.readlines()[1:]]\n",
    "with open(r'data\\morphynet\\suffixes.csv') as file:\n",
    "    suffixes = [s[:-1] for s in file.readlines()[1:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e87877",
   "metadata": {},
   "source": [
    "#### Phase 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3dd98798",
   "metadata": {},
   "outputs": [],
   "source": [
    "def use_tree(tree, reg):\n",
    "    reg_words = [word for word in reg.split(tree.text) if word != ' ' and word != '']\n",
    "    tree_words = []\n",
    "    for word in tree:\n",
    "        if word._form is not None and word.head is not None:\n",
    "            word_s = reg.sub('', word._form)\n",
    "            if word_s:\n",
    "                tree_words.append(word_s)\n",
    "    if reg_words == tree_words:\n",
    "        return True\n",
    "    if len(reg_words) == len(tree_words):\n",
    "        nts_match = True\n",
    "        for r, t in zip(reg_words, tree_words):\n",
    "            if r != t and r[-1] != 'n' and t != 'nt':\n",
    "                nts_match = False\n",
    "                break\n",
    "        return nts_match\n",
    "    \n",
    "    \n",
    "def train_tree_tokenizer(directory_path, filepath, prefixes, suffixes, spm_vocab_size: int, spm_model_type: str='bpe', min_stem: int=3):\n",
    "    words = []\n",
    "    reg = re.compile(r'[^\\p{L}\\p{M}\\p{N}\\s]+|\\s')\n",
    "    for tree in iter_from_file(filepath):\n",
    "        if use_tree(tree, reg):\n",
    "            for word in tree:\n",
    "                if word._form is not None and word.head is not None:\n",
    "                    word_s = reg.sub('', word._form)\n",
    "                    if word_s:\n",
    "                        words.append(word_s)\n",
    "    train_mopiece(directory_path, words, prefixes, suffixes, spm_vocab_size, spm_model_type, min_stem, False)\n",
    "\n",
    "\n",
    "class TreeDataset(pt.utils.data.Dataset):\n",
    "    def __init__(self, filepath, mopiece):\n",
    "        reg = re.compile(r'[^\\p{L}\\p{M}\\p{N}\\s]+|\\s')\n",
    "        self.labels = []\n",
    "        self.prefix_ids = []\n",
    "        self.spm_ids = []\n",
    "        self.suffix_ids = []\n",
    "        bos_id = mopiece.bos_id()\n",
    "        eos_id = mopiece.eos_id()\n",
    "        for tree in iter_from_file(filepath):\n",
    "            if use_tree(tree, reg):\n",
    "                labels = []\n",
    "                prefix_ids = []\n",
    "                spm_ids = []\n",
    "                suffix_ids = []\n",
    "                skipped_ids = []\n",
    "                for word in tree:\n",
    "                    if word._form is not None and word.head is not None:\n",
    "                        word_s = reg.sub('', word._form)\n",
    "                        if word_s:\n",
    "                            word_prefix_ids, word_spm_ids, word_suffix_ids = mopiece.encode_word(word_s)\n",
    "                            prefix_ids.append([bos_id] + word_prefix_ids + [eos_id])\n",
    "                            spm_ids.append([bos_id] + word_spm_ids + [eos_id])\n",
    "                            suffix_ids.append([bos_id] + word_suffix_ids + [eos_id])\n",
    "                            labels.append(int(word.head))\n",
    "                            continue\n",
    "                    if '-' not in word.id and '.' not in word.id:\n",
    "                        skipped_ids.append(int(word.id))\n",
    "                self.prefix_ids.append(prefix_ids)\n",
    "                self.spm_ids.append(spm_ids)\n",
    "                self.suffix_ids.append(suffix_ids)\n",
    "                for i, label in enumerate(labels):\n",
    "                    labels[i] -= sum([label >= j for j in skipped_ids])\n",
    "                self.labels.append(pt.tensor(labels, dtype=pt.long))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.prefix_ids[index], self.spm_ids[index], self.suffix_ids[index], self.labels[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4366ba11",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tree_tokenizer('____tree_tokenizer', 'data/treebank/en_ewt-ud-train.conllu', prefixes, suffixes, 3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5fd087",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_mopiece = MOPiece('____tree_tokenizer')\n",
    "train_dset = TreeDataset(r'data\\treebank\\en_ewt-ud-train.conllu', tree_mopiece)\n",
    "test_dset = TreeDataset(r'data\\treebank\\en_ewt-ud-test.conllu', tree_mopiece)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a80b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_id = tree_mopiece.pad_id()\n",
    "\n",
    "def collate_fn(batch):\n",
    "    def handle_component(i):\n",
    "        max_len = max_sublen = 0\n",
    "        for tup in batch:\n",
    "            seq = tup[i]\n",
    "            max_len = max(max_len, len(seq))\n",
    "            for subseq in seq:\n",
    "                max_sublen = max(max_sublen, len(subseq))\n",
    "        tensor = []\n",
    "        for tup in batch:\n",
    "            seq = tup[i]\n",
    "            tensor_seq = []\n",
    "            for subseq in seq:\n",
    "                tensor_seq.append(subseq + [pad_id] * (max_sublen - len(subseq)))\n",
    "            for _ in range(max_len - len(seq)):\n",
    "                tensor_seq.append([pad_id] * max_sublen)\n",
    "            tensor.append(tensor_seq)\n",
    "        return pt.tensor(tensor, dtype=pt.long)\n",
    "\n",
    "    return handle_component(0), handle_component(1), handle_component(2), nn.utils.rnn.pad_sequence([labels for prefix, spm, suffix, labels in batch], batch_first=True, padding_value=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f68df0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = WordEncoder(tree_mopiece.vocab_size(), tree_mopiece.pad_id(), 256, ffn_hidden_dim=512, expansion_factor=4, spm_layers=6, suffix_depth=4, prefix_depth=4).to(device)\n",
    "parser = DependencyParser(256, dropout=.1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ba431a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daad716c329a49d88d6f146ddfaa6b4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a84067bd3e2646a9b9c90e12a600bebf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/1359 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dae88409a0b47f590f2a74023138b5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/222 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d46bb78009564955b5f0a79819d322e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/1359 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caf2f588ee74478caf9d374b337e26c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/222 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2309731b64d46719fe20bcc2bf161ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/1359 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f35150713d049e5ab097c2664dea681",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/222 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "815e5395c3a54402967e826341cfdfbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/1359 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52db1390efeb488390c91fdd1973ab03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/222 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85fc6f6fed984ff6b7b7333b0bce2ca3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/1359 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b24560b47e584153abc01c50a0c7397d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/222 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34c67841fbaa4565962f9266eaf7d182",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/1359 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc0ba460a3ed44fab5422ab2ce8dbafe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/222 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21a48d672ab54fd1bbb9bae4f97b5184",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/1359 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e8d13712b4f4c7f9c36b3cd95b7ce91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/222 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "970879179ed54391a6b3a7af55381231",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/1359 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be1ca7dd09534f048a3d659497493511",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/222 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8aeed73efb9943f0bc63c3bcfb858718",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/1359 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cca4f97231a14e2db665c2270440dd41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/222 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0dd4d45eb64470e8c73def5c789413b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/1359 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5271612280de4d7a9819f591f8536c86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/222 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "821a33ba1b7847699ec3c3b31463ee7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/1359 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59fc16fe24ce4498aafa82937111ebe1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/222 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eec0c2e9128949fa83494e9ea7203a3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/1359 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ad70b7455014999a3294b233ae3a235",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/222 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae71d73fbfcb430c84a5d0f2f4c6b295",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/1359 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c373e62702f4e03a3b3c1b9ec6b7b3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/222 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3580c6ea10344c52a797c5671c31b822",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/1359 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ae91ec4e2b94c1d923c53a4b7a795b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/222 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efdf4e2b4abf41429973284afb910679",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/1359 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a46931057e44719897d518ca42ae292",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/222 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f507467024d4d358d8c7d9e80fe1a18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/1359 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d4bea443eb542aeb1eee81f37c03a09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/222 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0899f2211c64ebeaebdbb093d4d896d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/1359 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82a6410655c04b6bbc9c0898d534fb76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/222 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3515de0c3ba6469d92e93c71efe2fc3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/1359 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4437274ae8564d869f960b39cef2e68e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/222 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "507938090fed40559c89df10939ff933",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/1359 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0872939c189a4c28a926d9f55a90443c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/222 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc3a110276c9423cb677b4622cacefed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/1359 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df715496b8754a96a289ff656f2c6060",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/222 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95f68c38e94048f785ac1715898bd12a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/1359 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e275a54a4b784111845feabd1eeaa30e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/222 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48befaac200542f0a016dc7f43d81297",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/1359 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05958ded78c349c79403ecf747632d72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/222 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ff2f8930fcc4133866207a9a1feb840",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/1359 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09ce73d11aab43fb9a5fd59f6d542a98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/222 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79a08b17cbcb49d78d88701fb3a5edf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/1359 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "646c49007fcd4ce4947fd9cc7106ee8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/222 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c06f3cdb4bf6408ba463aa619667e6d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/1359 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b85466767ca4c4b948e41de14c319c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/222 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "293442bf9d214bf18968539ed51a8e17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/1359 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8de33522db534fafb19344b210f7f797",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/222 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4dab50d64534b29831eb82eb7a2380a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/1359 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d7d96d4bb194cb99934b5895c59a215",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/222 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f0d9a87995046a4a89621158fbfcc76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/1359 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad6f4b6df4794dc1ae2ce75d9b8d2c5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/222 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "368cb648a3fb487889e6bea2e28a3d47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/1359 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd20f2caf9584e6da16fed08605db464",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/222 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ab78abea54b49f6820e3047bbf74941",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/1359 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b22f569df044dc997fc92fbe6485729",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/222 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loader = pt.utils.data.DataLoader(train_dset, batch_size=8, shuffle=True, collate_fn=collate_fn, pin_memory=True, drop_last=True)\n",
    "test_loader = pt.utils.data.DataLoader(test_dset, batch_size=8, collate_fn=collate_fn, pin_memory=True, drop_last=True)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=-1, label_smoothing=.1)\n",
    "\n",
    "epochs = 30\n",
    "accumulate_grad = 2\n",
    "\n",
    "optim = pt.optim.AdamW([\n",
    "    {\"params\": encoder.parameters()},\n",
    "    {\"params\": parser.parameters()}\n",
    "], weight_decay=0.01, lr=3e-4)\n",
    "lr_scheduler = pt.optim.lr_scheduler.CosineAnnealingLR(optim, epochs)\n",
    "\n",
    "encoder.train()\n",
    "parser.train()\n",
    "\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "test_accuracies = []\n",
    "for epoch in (pbar := trange(epochs, desc='Epoch')):\n",
    "    train_loss_sum = 0\n",
    "    optim.zero_grad()\n",
    "    for i, (prefix_ids, spm_ids, suffix_ids, labels) in enumerate(tqdm(train_loader, desc='Training', leave=False)):\n",
    "        prefix_ids = prefix_ids.to(device)\n",
    "        spm_ids = spm_ids.to(device)\n",
    "        suffix_ids = suffix_ids.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        embeddings = encoder(prefix_ids, spm_ids, suffix_ids)\n",
    "        logits = parser(embeddings, labels != -1)\n",
    "\n",
    "        loss = criterion(logits.flatten(end_dim=-2), labels.flatten())\n",
    "        loss.backward()\n",
    "\n",
    "        if (i + 1) % accumulate_grad == 0:\n",
    "            optim.step()\n",
    "            optim.zero_grad()\n",
    "\n",
    "        train_loss_sum += loss.item()\n",
    "\n",
    "    train_loss = train_loss_sum / len(train_loader)\n",
    "    train_losses.append(train_loss)\n",
    "    with pt.no_grad():\n",
    "        test_loss_sum = 0.\n",
    "        hits = 0\n",
    "        total = 0\n",
    "        for prefix_ids, spm_ids, suffix_ids, labels in tqdm(test_loader, desc='Evaluating', leave=False):\n",
    "            prefix_ids = prefix_ids.to(device)\n",
    "            spm_ids = spm_ids.to(device)\n",
    "            suffix_ids = suffix_ids.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            embeddings = encoder(prefix_ids, spm_ids, suffix_ids)\n",
    "            logits = parser(embeddings, labels != -1).flatten(end_dim=-2)\n",
    "\n",
    "            logits = logits.flatten(end_dim=-2)\n",
    "            labels = labels.flatten()\n",
    "\n",
    "            test_loss_sum += criterion(logits, labels).item()\n",
    "            hits += pt.sum(logits.argmax(-1) == labels).item()\n",
    "            total += pt.sum(labels != -1).item()\n",
    "\n",
    "    test_loss = test_loss_sum / len(test_loader)\n",
    "    test_losses.append(test_loss)\n",
    "    test_acc = hits / total\n",
    "    test_accuracies.append(test_acc)\n",
    "    pbar.set_postfix_str(f'train loss: {train_loss:.2f}, test loss: {test_loss:.2f}, test accuracy: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "729b275b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2951cbf4620>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(test_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7330b92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt.save(encoder.state_dict(), '____tree_encoder.pt')\n",
    "pt.save(parser.state_dict(), '____tree_parser.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a77e556b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.load_state_dict(pt.load('____tree_encoder.pt', weights_only=True))\n",
    "parser.load_state_dict(pt.load('____tree_parser.pt', weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ddbf0b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'pretty', 'horse', 'landed', 'on', 'the', 'green', 'grass']\n",
      "['a->horse', 'pretty->horse', 'horse->landed', 'landed->ROOT', 'on->grass', 'the->grass', 'green->grass', 'grass->landed']\n"
     ]
    }
   ],
   "source": [
    "with pt.no_grad():\n",
    "    encoder.eval()\n",
    "    parser.eval()\n",
    "    bos_id, eos_id = tree_mopiece.bos_id(), tree_mopiece.eos_id()\n",
    "    input_sentence = input()\n",
    "    words = input_sentence.split()\n",
    "    print(words)\n",
    "    embeddings = []\n",
    "    for word in words:\n",
    "        prefix_ids, spm_ids, suffix_ids = map(lambda x: [bos_id] + x + [eos_id], tree_mopiece.encode_word(word))\n",
    "        embedding = encoder(pt.tensor(prefix_ids, dtype=pt.long, device=device), pt.tensor(spm_ids, dtype=pt.long, device=device), pt.tensor(suffix_ids, dtype=pt.long, device=device))\n",
    "        embeddings.append(embedding.unsqueeze(0))\n",
    "    heads = parser.inference(pt.cat(embeddings, dim=-2))\n",
    "    root_words = ['ROOT'] + words\n",
    "    for i, head in enumerate(heads):\n",
    "        words[i] += f'->{root_words[head]}'\n",
    "    print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f595ce8",
   "metadata": {},
   "source": [
    "#### Phase 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2731216a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_mopiece = MOPiece('____tree_tokenizer')\n",
    "encoder = WordEncoder(tree_mopiece.vocab_size(), tree_mopiece.pad_id(), 256, ffn_hidden_dim=512, expansion_factor=4, spm_layers=6, suffix_depth=4, prefix_depth=4).to(device)\n",
    "parser = DependencyParser(256, dropout=.1).to(device)\n",
    "encoder.load_state_dict(pt.load('____tree_encoder.pt', weights_only=True))\n",
    "parser.load_state_dict(pt.load('____tree_parser.pt', weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f3b0764",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"lucadiliello/bookcorpusopen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5200744e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "k = 1000\n",
    "def texts():\n",
    "    idxs = list(range(len(ds['train'])))\n",
    "    shuffle(idxs)\n",
    "    for i in idxs[:k]:\n",
    "        yield ds['train'][i]['text']\n",
    "train_mopiece('____bookcorpus_tokenizer', texts(), prefixes, suffixes, 10000, filepaths=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e22a7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mopiece = MOPiece('____bookcorpus_tokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "463b7170",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randrange\n",
    "\n",
    "class BookCorpusInfiniteDataloader:\n",
    "    def __init__(self, dset, chunk_size_min=64, chunk_size_max=256):\n",
    "        self.dset = dset\n",
    "        self.chunk_size_min = chunk_size_min\n",
    "        self.chunk_size_max = chunk_size_max\n",
    "        self.reg = re.compile(r'[^\\p{L}\\p{M}\\p{N}\\s]+|\\s')\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        while True:\n",
    "            try:\n",
    "                idx = randrange(len(self.dset))\n",
    "                encoder_chunk_size = randrange(self.chunk_size_min, self.chunk_size_max + 1)\n",
    "                decoder_chunk_size = randrange(self.chunk_size_min, self.chunk_size_max + 1)\n",
    "                total_chunk_size = encoder_chunk_size + decoder_chunk_size\n",
    "                text = self.dset[idx]['text']\n",
    "                max_idx = len(text) - total_chunk_size\n",
    "                if max_idx < 0:\n",
    "                    continue\n",
    "                start_idx = randrange(max_idx + 1)\n",
    "                middle_idx = start_idx + encoder_chunk_size\n",
    "                end_idx = middle_idx + decoder_chunk_size\n",
    "                m = self.reg.search(text, start_idx, middle_idx)\n",
    "                if m is None:\n",
    "                    continue\n",
    "                start_idx = m.end()\n",
    "                m = self.reg.search(text, middle_idx, end_idx)\n",
    "                if m is None:\n",
    "                    continue\n",
    "                middle_idx = m.end()\n",
    "                m = self.reg.search(text, end_idx)\n",
    "                if m is None:\n",
    "                    continue\n",
    "                end_idx = m.end()\n",
    "                if start_idx == middle_idx or middle_idx == end_idx:\n",
    "                    continue\n",
    "                return text[start_idx:middle_idx], text[middle_idx:end_idx]\n",
    "            except:\n",
    "                pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "409886c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 512\n",
    "\n",
    "word_encoder = WordEncoder(mopiece.vocab_size(), mopiece.pad_id(), embedding_dim, ffn_hidden_dim=embedding_dim * 2, expansion_factor=4, spm_layers=6, suffix_depth=4, prefix_depth=4).to(device)\n",
    "word_decoder = WordDecoder(mopiece.vocab_size(), mopiece.pad_id(), mopiece.bos_id(), mopiece.eos_id(), embedding_dim, num_layers=8, expansion_factor=2).to(device)\n",
    "transformer = Transformer(embedding_dim).to(device)\n",
    "moplm = MOPLM(word_encoder, word_decoder, transformer).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bba981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae772f308f8e4fbeae65d34bcf92c0b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99401661836e43028e0fd06e9ff449cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bos_id, eos_id, pad_id = mopiece.bos_id(), mopiece.eos_id(), mopiece.pad_id()\n",
    "\n",
    "xent = nn.CrossEntropyLoss(ignore_index=pad_id, label_smoothing=.1)\n",
    "criterion = lambda logits, labels: xent(logits.flatten(end_dim=-2), labels.flatten())\n",
    "\n",
    "loader = BookCorpusInfiniteDataloader(ds['train'])\n",
    "\n",
    "epoch_steps = 100\n",
    "gradient_accumulation = 2\n",
    "\n",
    "optim = pt.optim.AdamW(moplm.parameters(), weight_decay=0.01, lr=3e-4)\n",
    "lr_scheduler = pt.optim.lr_scheduler.ReduceLROnPlateau(optim, factor=.5, patience=10, cooldown=10)\n",
    "\n",
    "moplm.train()\n",
    "\n",
    "reg = re.compile(r'([^\\p{L}\\p{M}\\p{N}\\s]+|\\s)')\n",
    "\n",
    "losses = []\n",
    "step = 0\n",
    "pbar = tqdm(desc='Epochs')\n",
    "epoch_pbar = tqdm(desc='Training', total=epoch_steps, leave=False)\n",
    "epoch_loss_sum = 0.\n",
    "optim.zero_grad()\n",
    "for encoder_text, decoder_text in loader:\n",
    "\n",
    "    context_prefix_ids, context_spm_ids, context_suffix_ids = map(lambda x: [[bos_id] + seq + [eos_id] for seq in x[0]], mopiece.encode([encoder_text]))\n",
    "    \n",
    "    tokens = []\n",
    "    words = []\n",
    "    word_indices = []\n",
    "    idx = 0\n",
    "    for word in reg.split(decoder_text):\n",
    "        if word == ' ' or word == '':\n",
    "            continue\n",
    "        word = word.lower()\n",
    "        if not reg.search(word):\n",
    "            words.append(word)\n",
    "            word_indices.append(idx)\n",
    "        tokens.append(word)\n",
    "        idx += 1\n",
    "\n",
    "    embeddings = []\n",
    "    for word in words:\n",
    "        prefix_ids, spm_ids, suffix_ids = map(lambda x: [bos_id] + x + [eos_id], tree_mopiece.encode_word(word))\n",
    "        embedding = encoder(pt.tensor(prefix_ids, dtype=pt.long, device=device), pt.tensor(spm_ids, dtype=pt.long, device=device), pt.tensor(suffix_ids, dtype=pt.long, device=device))\n",
    "        embeddings.append(embedding.unsqueeze(0))\n",
    "    heads = parser.inference(pt.cat(embeddings, dim=-2))\n",
    "    word_depths = []\n",
    "    for head in heads:\n",
    "        depth = 0\n",
    "        while head:\n",
    "            head = heads[head - 1]\n",
    "            depth += 1\n",
    "        word_depths.append(depth)\n",
    "    \n",
    "    max_depth = max(word_depths) + 1\n",
    "    token_depths = [max_depth] * len(tokens)\n",
    "    for idx, depth in zip(word_indices, word_depths):\n",
    "        token_depths[idx] = depth\n",
    "    \n",
    "    input_prefix_ids = [[bos_id, eos_id]]\n",
    "    input_spm_ids = [[bos_id, eos_id]]\n",
    "    input_suffix_ids = [[bos_id, eos_id]]\n",
    "    input_depths = [max_depth + 1]\n",
    "    input_is_pad = [True]\n",
    "    output_prefix_ids = [[bos_id, eos_id]]\n",
    "    output_spm_ids = [[bos_id, eos_id]]\n",
    "    output_suffix_ids = [[bos_id, eos_id]]\n",
    "    for depth, token in zip(token_depths, tokens):\n",
    "        prefix_ids, spm_ids, suffix_ids = mopiece.encode_word(token)\n",
    "        input_prefix_ids.append([bos_id] + prefix_ids + [eos_id])\n",
    "        input_spm_ids.append([bos_id] + spm_ids + [eos_id])\n",
    "        input_suffix_ids.append([bos_id] + suffix_ids + [eos_id])\n",
    "        input_depths.append(depth)\n",
    "        input_is_pad.append(False)\n",
    "        \n",
    "        for pad_depth in (depth, max_depth + 1):\n",
    "            for l in (input_prefix_ids, input_spm_ids, input_suffix_ids):\n",
    "                l.append([bos_id, eos_id])\n",
    "            input_depths.append(pad_depth)\n",
    "            input_is_pad.append(True)\n",
    "\n",
    "        for _ in range(2):\n",
    "            output_prefix_ids.append([bos_id] + prefix_ids + [eos_id])\n",
    "            output_spm_ids.append([bos_id] + spm_ids + [eos_id])\n",
    "            output_suffix_ids.append([bos_id] + suffix_ids + [eos_id])\n",
    "\n",
    "        for l in (output_prefix_ids, output_spm_ids, output_suffix_ids):\n",
    "            l.append([bos_id, eos_id])\n",
    "    \n",
    "    attn_mask = []\n",
    "    for depth_i, pad_i in zip(input_depths, input_is_pad):\n",
    "        attn_mask_row = []\n",
    "        for depth_j, pad_j in zip(input_depths, input_is_pad):\n",
    "            attn_mask_row.append((depth_i >= depth_j + (pad_i and not pad_j)) and (pad_i or not pad_j))\n",
    "        attn_mask.append(attn_mask_row)\n",
    "    \n",
    "    attn_mask = pt.tensor(attn_mask, dtype=pt.bool, device=device)\n",
    "\n",
    "    input_prefix_ids, input_spm_ids, input_suffix_ids, context_prefix_ids, context_spm_ids, context_suffix_ids, output_prefix_ids, output_spm_ids, output_suffix_ids = map(lambda x: nn.utils.rnn.pad_sequence([pt.tensor(seq, dtype=pt.long, device=device) for seq in x], batch_first=True, padding_value=pad_id), (input_prefix_ids, input_spm_ids, input_suffix_ids, context_prefix_ids, context_spm_ids, context_suffix_ids, output_prefix_ids, output_spm_ids, output_suffix_ids))\n",
    "    \n",
    "    prefix_logits, spm_logits, suffix_logits = moplm.forward(input_prefix_ids, input_spm_ids, input_suffix_ids, context_prefix_ids, context_spm_ids, context_suffix_ids, output_prefix_ids[:, :-1], output_spm_ids[:, :-1], output_suffix_ids[:, :-1], attn_mask)\n",
    "    \n",
    "    loss = criterion(prefix_logits, output_prefix_ids[:, 1:]) + criterion(spm_logits, output_spm_ids[:, 1:]) + criterion(suffix_logits, output_suffix_ids[:, 1:])\n",
    "    loss.backward()\n",
    "\n",
    "    epoch_loss_sum += loss.item()\n",
    "\n",
    "    step += 1\n",
    "    epoch_pbar.update()\n",
    "    if step % gradient_accumulation == 0:\n",
    "        optim.step()\n",
    "        nn.utils.clip_grad_norm_(moplm.parameters(), 5.)\n",
    "        optim.zero_grad()\n",
    "\n",
    "    if step % epoch_steps == 0:\n",
    "        epoch_loss = epoch_loss_sum / epoch_steps\n",
    "        epoch_loss_sum = 0.\n",
    "        lr_scheduler.step(epoch_loss)\n",
    "        losses.append(epoch_loss)\n",
    "        pbar.update()\n",
    "        pbar.set_postfix_str(f'loss: {epoch_loss:.2f}, lr: {lr_scheduler.get_last_lr()[0]:.2e}')\n",
    "        epoch_pbar.close()\n",
    "        epoch_pbar = tqdm(desc='Training', total=epoch_steps, leave=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0d64e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt.save(moplm.state_dict(), '____moplm.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7889fe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moplm.load_state_dict(pt.load('____moplm.pt', weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7348445a",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m mopiece\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m x: [x], \u001b[43mmoplm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minference\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmopiece\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minference_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmax_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)))\n",
      "File \u001b[1;32mc:\\Users\\ATRTi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ATRTi\\Desktop\\MOP-LM\\MOP-LM\\moplm.py:153\u001b[0m, in \u001b[0;36mMOPLM.inference\u001b[1;34m(self, context_prefix_ids, context_spm_ids, context_suffix_ids, add_tags, beam_search, inference_kwargs, max_iters)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, output_embedding \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(output_embeddings[::\u001b[38;5;241m2\u001b[39m]):\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m beam_search:\n\u001b[1;32m--> 153\u001b[0m         prefix_ids, spm_ids, suffix_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mword_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbeam_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_embedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minference_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    154\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m         prefix_ids, spm_ids, suffix_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mword_decoder\u001b[38;5;241m.\u001b[39minference(output_embedding, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minference_kwargs)\n",
      "File \u001b[1;32mc:\\Users\\ATRTi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ATRTi\\Desktop\\MOP-LM\\MOP-LM\\word_autoencoder.py:346\u001b[0m, in \u001b[0;36mWordDecoder.beam_search\u001b[1;34m(self, embedding, beam_size, max_len, length_penalty)\u001b[0m\n\u001b[0;32m    328\u001b[0m prefix_ids \u001b[38;5;241m=\u001b[39m _beam_search_component(\n\u001b[0;32m    329\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprefix_proj(embedding),\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprefix_embedding,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    334\u001b[0m     max_len[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    335\u001b[0m )\n\u001b[0;32m    337\u001b[0m spm_ids \u001b[38;5;241m=\u001b[39m _beam_search_component(\n\u001b[0;32m    338\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspm_proj(embedding),\n\u001b[0;32m    339\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspm_embedding,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    343\u001b[0m     max_len[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    344\u001b[0m )\n\u001b[1;32m--> 346\u001b[0m suffix_ids \u001b[38;5;241m=\u001b[39m \u001b[43m_beam_search_component\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuffix_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuffix_embedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuffix_decoder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuffix_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuffix_linear\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_len\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m prefix_ids, spm_ids, suffix_ids\n",
      "File \u001b[1;32mc:\\Users\\ATRTi\\Desktop\\MOP-LM\\MOP-LM\\word_autoencoder.py:302\u001b[0m, in \u001b[0;36mWordDecoder.beam_search.<locals>._beam_search_component\u001b[1;34m(emb_proj, embedding_fn, decoder, norm_fn, classifier_fn, max_seq_len)\u001b[0m\n\u001b[0;32m    299\u001b[0m curr_emb \u001b[38;5;241m=\u001b[39m embedding_fn(curr_input_ids)\n\u001b[0;32m    300\u001b[0m curr_input \u001b[38;5;241m=\u001b[39m pt\u001b[38;5;241m.\u001b[39mcat([emb_proj, curr_emb], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m--> 302\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_decode_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurr_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclassifier_fn\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :]\n\u001b[0;32m    304\u001b[0m log_probs \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mlog_softmax(logits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    305\u001b[0m topk_log_probs, topk_indices \u001b[38;5;241m=\u001b[39m log_probs\u001b[38;5;241m.\u001b[39mtopk(beam_size)\n",
      "File \u001b[1;32mc:\\Users\\ATRTi\\Desktop\\MOP-LM\\MOP-LM\\word_autoencoder.py:152\u001b[0m, in \u001b[0;36mWordDecoder._decode_sequence\u001b[1;34m(self, input_emb, decoder, final_norm, classifier)\u001b[0m\n\u001b[0;32m    150\u001b[0m L \u001b[38;5;241m=\u001b[39m input_emb\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m    151\u001b[0m mask \u001b[38;5;241m=\u001b[39m pt\u001b[38;5;241m.\u001b[39mtril(pt\u001b[38;5;241m.\u001b[39mones((\u001b[38;5;241m*\u001b[39mbatch_shape, L, L), device\u001b[38;5;241m=\u001b[39minput_emb\u001b[38;5;241m.\u001b[39mdevice, dtype\u001b[38;5;241m=\u001b[39mpt\u001b[38;5;241m.\u001b[39mbool))\n\u001b[1;32m--> 152\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m classifier(final_norm(\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_emb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m))\n",
      "File \u001b[1;32mc:\\Users\\ATRTi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ATRTi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\ATRTi\\Desktop\\MOP-LM\\MOP-LM\\common.py:264\u001b[0m, in \u001b[0;36mEncoder.forward\u001b[1;34m(self, x, attn_mask)\u001b[0m\n\u001b[0;32m    262\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_layers):\n\u001b[0;32m    263\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mMHSAs[i](\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorms[\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m i](x), attn_mask)\n\u001b[1;32m--> 264\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mFFNs[i](\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorms\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    265\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\ATRTi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ATRTi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\ATRTi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\normalization.py:401\u001b[0m, in \u001b[0;36mRMSNorm.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    397\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m    398\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;124;03m    Runs forward pass.\u001b[39;00m\n\u001b[0;32m    400\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 401\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrms_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalized_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ATRTi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\functional.py:2929\u001b[0m, in \u001b[0;36mrms_norm\u001b[1;34m(input, normalized_shape, weight, eps)\u001b[0m\n\u001b[0;32m   2925\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_variadic(\u001b[38;5;28minput\u001b[39m, weight):\n\u001b[0;32m   2926\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m   2927\u001b[0m         rms_norm, (\u001b[38;5;28minput\u001b[39m, weight), \u001b[38;5;28minput\u001b[39m, normalized_shape, weight\u001b[38;5;241m=\u001b[39mweight, eps\u001b[38;5;241m=\u001b[39meps\n\u001b[0;32m   2928\u001b[0m     )\n\u001b[1;32m-> 2929\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrms_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalized_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mopiece.decode(tuple(map(lambda x: [x], moplm.inference(*map(lambda x: x[0], mopiece.encode([input()])), max_iters=5, inference_kwargs=dict(max_len=10)))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
